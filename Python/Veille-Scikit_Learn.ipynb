{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bibliothèque permettant de déployer des outils statistiques utiles pour le machine learning dans du code python ; basé sur Numpy et Scipy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse prédictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     pregnant  diastolic  triceps  bodymass  pedigree  age  plasma  serum  \\\n",
      "0           6         72       35      33.6     0.627   50     148      0   \n",
      "1           1         66       29      26.6     0.351   31      85      0   \n",
      "2           8         64        0      23.3     0.672   32     183      0   \n",
      "3           1         66       23      28.1     0.167   21      89     94   \n",
      "4           0         40       35      43.1     2.288   33     137    168   \n",
      "..        ...        ...      ...       ...       ...  ...     ...    ...   \n",
      "763        10         76       48      32.9     0.171   63     101    180   \n",
      "764         2         70       27      36.8     0.340   27     122      0   \n",
      "765         5         72       23      26.2     0.245   30     121    112   \n",
      "766         1         60        0      30.1     0.349   47     126      0   \n",
      "767         1         70       31      30.4     0.315   23      93      0   \n",
      "\n",
      "      diabete  \n",
      "0    positive  \n",
      "1    negative  \n",
      "2    positive  \n",
      "3    negative  \n",
      "4    positive  \n",
      "..        ...  \n",
      "763  negative  \n",
      "764  negative  \n",
      "765  negative  \n",
      "766  positive  \n",
      "767  negative  \n",
      "\n",
      "[768 rows x 9 columns]\n",
      "(768, 9)\n",
      "Index(['pregnant', 'diastolic', 'triceps', 'bodymass', 'pedigree', 'age',\n",
      "       'plasma', 'serum', 'diabete'],\n",
      "      dtype='object')\n",
      "pregnant       int64\n",
      "diastolic      int64\n",
      "triceps        int64\n",
      "bodymass     float64\n",
      "pedigree     float64\n",
      "age            int64\n",
      "plasma         int64\n",
      "serum          int64\n",
      "diabete       object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "#utilisation de la librairie Pandas spécialisée - entres autres - dans la manipulation des données\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "pima = pd.read_table(\"http://eric.univ-lyon2.fr/~rrado/files/pima.txt\",sep=\"\\t\",header=0)\n",
    "# pima = datasets.load_diabetes(return_X_y=False, as_frame=False)\n",
    "\n",
    "print(pima)\n",
    "\n",
    "#dimensions\n",
    "print(pima.shape)\n",
    "\n",
    "#liste des colonnes\n",
    "print(pima.columns)\n",
    "\n",
    "#liste des colonnes et leurs types\n",
    "print(pima.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subdivision en échantillons d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 8) (300, 8) (468,) (300,)\n"
     ]
    }
   ],
   "source": [
    "#transformation en matrice numpy\n",
    "data = pima.values\n",
    "\n",
    "#X matrice des var. explicatives\n",
    "X = data[:,0:8]\n",
    "\n",
    "#y vecteur de la var. à prédire\n",
    "y = data[:,8]\n",
    "\n",
    "#utilisation du module model_selection de scikit-learn (sklearn)\n",
    "from sklearn import model_selection\n",
    "\n",
    "#subdivision des données – éch.test = 300 ; éch.app = 768 – éch.test = 468\n",
    "X_app,X_test,y_app,y_test = model_selection.train_test_split(X,y,test_size = 300,random_state=0)\n",
    "\n",
    "print(X_app.shape,X_test.shape,y_app.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction du modèle sur l’échantillon d’apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.75153769e-02 -1.59511103e-02  1.70428483e-03  5.18609374e-02\n",
      "   5.34696503e-01  1.24335202e-02  2.40115458e-02 -2.91586161e-04]] [-5.13527961]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#à partir du module linear_model du package sklearn\n",
    "#importer la classe LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#création d'une instance de la classe\n",
    "lr = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "#exécution de l'instance sur les données d'apprentissage\n",
    "#c.à-d. construction du modèle prédictif\n",
    "modele = lr.fit(X_app,y_app)\n",
    "\n",
    "#les sorties sont très pauvres à la différence des logiciels de stat\n",
    "#les coefficients...\n",
    "print(modele.coef_,modele.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prédiction et évaluation sur l’échantillon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[184  17]\n",
      " [ 45  54]]\n",
      "0.7933333333333333\n",
      "0.20666666666666667\n",
      "0.5454545454545454\n"
     ]
    }
   ],
   "source": [
    "#prediction sur l'échantillon test\n",
    "y_pred = modele.predict(X_test)\n",
    "\n",
    "#importation de metrics - utilisé pour les mesures de performances\n",
    "from sklearn import metrics\n",
    "\n",
    "#matrice de confusion\n",
    "#confrontation entre Y obs. sur l’éch. test et la prédiction\n",
    "cm = metrics.confusion_matrix(y_test,y_pred)\n",
    "print(cm)\n",
    "\n",
    "#taux de succès\n",
    "acc = metrics.accuracy_score(y_test,y_pred)\n",
    "print(acc) # 0.793 = (184 + 54)/ (184 + 17 + 45 + 54)\n",
    "\n",
    "#taux d'erreur\n",
    "err = 1.0 - acc\n",
    "print(err) # 0.206 = 1.0 – 0.793\n",
    "\n",
    "#sensibilité (ou rappel)\n",
    "se = metrics.recall_score(y_test,y_pred,pos_label='positive')\n",
    "print(se) # 0.545 = 54 / (45+ 54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construction de sa propre mesure de performance (ex. Spécificité)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9154228855721394\n"
     ]
    }
   ],
   "source": [
    "#écrire sa propre func. d'éval - ex. specificité\n",
    "def specificity(y,y_hat):\n",
    "    #matrice de confusion – un objet numpy.ndarray\n",
    "    mc = metrics.confusion_matrix(y,y_hat)\n",
    "    #\"negative\" est sur l'indice 0 dans la matrice\n",
    "    import numpy\n",
    "    res = mc[0,0]/numpy.sum(mc[0,:])\n",
    "    #retour\n",
    "    return res\n",
    "\n",
    "#la rendre utilisable - transformation en objet scorer\n",
    "specificite = metrics.make_scorer(specificity,greater_is_better=True)\n",
    "\n",
    "#utilisation de l’objet scorer\n",
    "#remarque : modele est le modèle élaboré sur l’éch. d’apprentissage\n",
    "sp = specificite(modele,X_test,y_test)\n",
    "print(sp) # 0.915 = 184 / (184 + 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pourquoi la validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.17087631e-01 -1.68947770e-02  7.46053001e-04  5.97221654e-02\n",
      "   6.81392866e-01  7.21999666e-03  2.83788475e-02 -6.42978367e-04]] [-5.88988049]\n",
      "[0.74025974 0.75324675 0.79220779 0.72727273 0.74025974 0.74025974\n",
      " 0.81818182 0.79220779 0.73684211 0.82894737]\n",
      "0.7669685577580314\n"
     ]
    }
   ],
   "source": [
    "#importer la classe LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#création d'une instance de la classe\n",
    "lr = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "#exécution de l'instance sur la totalité des données (X,y)\n",
    "modele_all = lr.fit(X,y)\n",
    "\n",
    "#affichage\n",
    "print(modele_all.coef_,modele_all.intercept_)# [[  1.17056955e-01  -1.69020125e-02   7.53362852e-04   5.96780492e-02 6.77559538e-01   7.21222074e-03   2.83668010e-02  -6.41169185e-04]] [-5.8844014]\n",
    "\n",
    "# !!! Les coefficients sont différents de ceux estimés sur l’éch. d’apprentissage (on a plus d’obs. ici) !!!\n",
    "#utilisation du module model_selection\n",
    "from sklearn import model_selection\n",
    "\n",
    "#évaluation en validation croisée : 10 cross-validation\n",
    "succes = model_selection.cross_val_score(lr,X,y,cv=10,scoring='accuracy')\n",
    "\n",
    "#détail des itérations\n",
    "print(succes)\n",
    "\n",
    "#moyenne des taux de succès = estimation du taux de succès en CV\n",
    "print(succes.mean()) # 0.767"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring - Ciblage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classe Régression Logistique\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#création d'une instance de la classe\n",
    "lr = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "#modélisation sur les données d'apprentissage\n",
    "modele = lr.fit(X_app,y_app)\n",
    "\n",
    "#calcul des probas d'affectation sur ech. test\n",
    "probas = lr.predict_proba(X_test)\n",
    "\n",
    "#score de 'presence'\n",
    "score = probas[:,1] # [0.86238322  0.21334963  0.15895063 ...]\n",
    "\n",
    "#transf. en 0/1 de Y_test\n",
    "pos = pandas.get_dummies(y_test).values\n",
    "\n",
    "#on ne récupère que la 2è colonne (indice 1)\n",
    "pos = pos[:,1] # [ 1  0  0  1  0  0  1  1 ...]\n",
    "\n",
    "#nombre total de positif\n",
    "import numpy\n",
    "npos = numpy.sum(pos) # 99 – il y a 99 ind. ‘’positifs’’  dans l’échantillon test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#index pour tri selon le score croissant\n",
    "index = numpy.argsort(score) # [ 55  45  265  261 ... 11  255  159]\n",
    "\n",
    "#inverser pour score décroissant – on s’intéresse à forte proba. en priorité\n",
    "index = index[::-1] # [ 159  255  11 ... 261  265  45  55 ]\n",
    "\n",
    "#tri des individus (des valeurs 0/1)\n",
    "sort_pos = pos[index] # [ 1  1  1  1  1  0  1  1 ...]\n",
    "\n",
    "#somme cumulée\n",
    "cpos = numpy.cumsum(sort_pos) # [ 1  2  3  4  5  5  6 7 ... 99]\n",
    "\n",
    "#rappel\n",
    "rappel = cpos/npos # [ 1/99  2/99  3/99  4/99  5/99  5/99  6/99  7/99 ... 99/99]\n",
    "\n",
    "#nb. obs ech.test\n",
    "n = y_test.shape[0] # 300, il y a 300 ind. dans l’éch. test\n",
    "\n",
    "#taille de cible – séquence de valeurs de 1 à 300 avec un pas de 1\n",
    "taille = numpy.arange(start=1,stop=301,step=1) # [1  2  3  4  5  ...  300]\n",
    "\n",
    "#passer en proportion\n",
    "taille = taille / n # [ 1/300  2/300  3/300 ... 300/300 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#graphique avec matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#titre et en-têtes\n",
    "plt.title('Courbe de gain')\n",
    "plt.xlabel('Taille de cible')\n",
    "plt.ylabel('Rappel')\n",
    "\n",
    "#limites en abscisse et ordonnée\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(0,1)\n",
    "\n",
    "#astuce pour tracer la diagonale\n",
    "plt.scatter(taille,taille,marker='.',color='blue')\n",
    "\n",
    "#insertion du couple (taille, rappel)\n",
    "plt.scatter(taille,rappel,marker='.',color='red')\n",
    "\n",
    "#affichage\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[184  17]\n",
      " [ 57  42]]\n",
      "0.7533333333333333\n"
     ]
    }
   ],
   "source": [
    "#svm\n",
    "from sklearn import svm\n",
    "\n",
    "#par défaut un noyau RBF et C = 1.0\n",
    "mvs = svm.SVC()\n",
    "\n",
    "#modélisation\n",
    "modele2 = mvs.fit(X_app,y_app)\n",
    "\n",
    "#prédiction ech. test\n",
    "y_pred2 = modele2.predict(X_test)\n",
    "\n",
    "#matrice de confusion\n",
    "print(metrics.confusion_matrix(y_test,y_pred2))\n",
    "\n",
    "#succès en test\n",
    "print(metrics.accuracy_score(y_test,y_pred2)) # 0.67"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           params  mean_test_score\n",
      "0     {'C': 0.1, 'kernel': 'rbf'}         0.647449\n",
      "1  {'C': 0.1, 'kernel': 'linear'}         0.762755\n",
      "2       {'C': 1, 'kernel': 'rbf'}         0.749989\n",
      "3    {'C': 1, 'kernel': 'linear'}         0.762755\n",
      "4      {'C': 10, 'kernel': 'rbf'}         0.728552\n",
      "5   {'C': 10, 'kernel': 'linear'}         0.760604\n",
      "{'C': 0.1, 'kernel': 'linear'}\n",
      "0.7627545184168383\n",
      "0.7866666666666666\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "#combinaisons de paramètres à évaluer\n",
    "parametres = [{'C':[0.1,1,10],'kernel':['rbf','linear']}]\n",
    "\n",
    "#évaluation en validation croisée de 3 x 2 = 6 configurations\n",
    "#accuracy sera le critère à utiliser pour sélectionner la meilleure config\n",
    "#mvs est l’instance de la classe svm.SVC (cf. page précédente)\n",
    "grid = model_selection.GridSearchCV(estimator=mvs,param_grid=parametres,scoring='accuracy')\n",
    "\n",
    "#lancer la recherche – attention, gourmand en calculs\n",
    "grille = grid.fit(X_app,y_app)\n",
    "\n",
    "#résultat pour chaque combinaison\n",
    "print(pandas.DataFrame.from_dict(grille.cv_results_).loc[:,[\"params\",\"mean_test_score\"]]) \n",
    "\n",
    "#meilleur paramétrage\n",
    "print(grille.best_params_) # {‘C’ : 10, ‘kernel’ : ‘linear’}\n",
    "\n",
    "#meilleur performance – estimée en interne par validation croisée\n",
    "print(grille.best_score_) # 0.7564\n",
    "\n",
    "#prédiction avec le modèle « optimal » c.-à-d. {‘C’ : 10, ‘kernel’ : ‘linear’}\n",
    "y_pred3 = grille.predict(X_test)\n",
    "\n",
    "#taux de succès en test\n",
    "print(metrics.accuracy_score(y_test,y_pred3)) # 0.7833, on se rapproche de la rég. logistique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sélection de variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "[ True False False  True  True False  True False]\n",
      "[1 2 4 1 1 3 1 5]\n"
     ]
    }
   ],
   "source": [
    "#importer la classe LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#création d'une instance de la classe\n",
    "lr = LogisticRegression(solver=\"liblinear\")\n",
    "\n",
    "#algorithme de sélection de var.\n",
    "from sklearn.feature_selection import RFE\n",
    "selecteur = RFE(estimator=lr)\n",
    "\n",
    "#lancer la recherche\n",
    "sol = selecteur.fit(X_app,y_app)\n",
    "\n",
    "#nombre de var. sélectionnées\n",
    "print(sol.n_features_) # 4 →4 = 8 / 2 variables sélectionnées\n",
    "\n",
    "#liste des variables sélectionnées\n",
    "print(sol.support_) # [True False False True True False True False ]\n",
    "\n",
    "#ordre de suppression\n",
    "print(sol.ranking_) # [1  2  4  1  1  3  1  5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(468, 4)\n",
      "(300, 4)\n",
      "0.7866666666666666\n"
     ]
    }
   ],
   "source": [
    "#réduction de la base d'app. aux var. sélectionnées\n",
    "#en utilisant le filtre booléen sol.support_\n",
    "X_new_app = X_app[:,sol.support_]\n",
    "print(X_new_app.shape) # (468, 4) →4 variables restantes\n",
    "\n",
    "#construction du modèle sur les explicatives sélectionnées\n",
    "modele_sel = lr.fit(X_new_app,y_app)\n",
    "\n",
    "#réduction de la base test aux mêmes variables\n",
    "X_new_test = X_test[:,sol.support_]\n",
    "print(X_new_test.shape) # (300, 4)\n",
    "\n",
    "#prédiction du modèle réduit sur l’éch. test\n",
    "y_pred_sel = modele_sel.predict(X_new_test)\n",
    "\n",
    "#évaluation\n",
    "print(metrics.accuracy_score(y_test,y_pred_sel)) # 0.787"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
